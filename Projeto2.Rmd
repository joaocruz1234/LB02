---
title: "Projeto2"
author: "Jo√£o Cruz"
date: "2025-11-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 1. Data Generation


```{r}
rm(list=ls())
```

n - number of individuals
p - number of biomarkers
seed - fixed on number 1


```{r}
set.seed(1)
n <- 100 + sample(1:20, size = 1); n
p <- 15 + sample(1:3, size = 1); p
cat("Individuals:", n, "\nBiomarkers:", p, "\n")
```

```{r}
n_normal <- round(0.50 * p)
n_lognormal <- round(0.25 * p)
n_gamma <- p - n_normal - n_lognormal # garante que soma = p
```

```{r}
#cria uma lista ordenada

dist_vec <- c(rep("normal", n_normal),
              rep("lognormal", n_lognormal),
              rep("gamma", n_gamma))
```


criar uma matriz n √ó p com colunas simuladas com uma distribui√ß√£o diferente.

```{r}
set.seed(1)
dados <- matrix(NA, n, p)

for (j in 1:p) {
  
  if (dist_vec[j] == "normal") {
    dados[, j] <- rnorm(n, mean = 50, sd = 10)
    
  } else if (dist_vec[j] == "lognormal") {
    dados[, j] <- rlnorm(n, meanlog = 3.5, sdlog = 0.5)
    
  } else if (dist_vec[j] == "gamma") {
    dados[, j] <- rgamma(n, shape = 4, scale = 10)
  }
}
```

Como o conjunto de biomarcadores n√£o corresponde a vari√°veis reais espec√≠ficas, opt√°mos por simular diferentes comportamentos estat√≠sticos frequentemente observados em dados biom√©dicos.

Alguns biomarcadores foram gerados com distribui√ß√£o Normal, adequada para vari√°veis cont√≠nuas com flutua√ß√µes sim√©tricas em torno de um valor fisiol√≥gico t√≠pico.

Outros seguem distribui√ß√µes Log-normal e Gamma, adequadas para medi√ß√µes positivas e assim√©tricas, comuns em concentra√ß√µes, taxas ou quantidades biol√≥gicas.

Esta diversidade de distribui√ß√µes permite simular um cen√°rio realista e robusto, adequado para testar os m√©todos de c√°lculo e otimiza√ß√£o pedidos no trabalho.

```{r}
# 5. Introdu√ß√£o de Missing Values (entre 5% e 10%)
set.seed(1)

prop_na <- runif(1, 0.05, 0.10) #um valor entre 5 e 10%
num_na <- round(n * p * prop_na) #quantos transformados em NA com round para arrendondar para o n√∫mero inteiro mais proximo

na_positions <- arrayInd(sample(n * p, num_na), .dim = c(n, p))
dados[na_positions] <- NA

cat("Missing values introduzidos:", num_na, "\n")
```

```{r}
dados <- as.data.frame(dados)
colnames(dados) <- paste0("Bio", 1:p)
```


```{r}
saveRDS(dados, "dados_biomarcadores.rds")
```





# 2. Base Function with Loops ---------------------------------------------------


```{r}
dados <- readRDS("dados_biomarcadores.rds")
```


```{r}
calc_similarity_loops <- function(dados) {
  n <- nrow(dados)
  p <- ncol(dados)
  S <- matrix(NA, n, n)

  for (i in 1:n) {
    for (j in 1:n) {

      dist_ij <- 0
      num <- 0
      den_x <- 0
      den_y <- 0
      mean_dif_sum <- 0
      count_ij <- 0
      
      # calcular m√©dias 
      xi_mean <- mean(as.numeric(dados[i, ]), na.rm = TRUE)
      xj_mean <- mean(as.numeric(dados[j, ]), na.rm = TRUE)
      threshold_ij <- (xi_mean + xj_mean) / 2

      for (k in 1:p) {
        xi <- dados[i, k]
        xj <- dados[j, k]

        if (is.na(xi) || is.na(xj)) next

        # Dist√¢ncia euclidiana (soma manual)
        dist_ij <- dist_ij + (xi - xj)^2

        # Correla√ß√£o manual
        num <- num + (xi - xi_mean) * (xj - xj_mean)
        den_x <- den_x + (xi - xi_mean)^2
        den_y <- den_y + (xj - xj_mean)^2

        # Diferen√ßa absoluta
        mean_dif_sum <- mean_dif_sum + abs(xi - xj)

        # Contagem
        if (xi > threshold_ij && xj > threshold_ij) {
          count_ij <- count_ij + 1
        }
      }

      dist_ij <- sqrt(dist_ij)

      denom <- sqrt(den_x) * sqrt(den_y)
      corr_ij <- ifelse(denom == 0, NA, num / denom)

      # m√©dia das diferen√ßas absolutas 
      mean_dif_ij <- mean_dif_sum / p

      S[i, j] <- (dist_ij + abs(corr_ij) + mean_dif_ij) / (count_ij + 1)
    }
  }

  return(S)
}

```


```{r}
matrix.loop <- calc_similarity_loops(dados)
```






Tratamento de valores em falta (NA): No conjunto de dados gerado, foi introduzida uma propor√ß√£o entre 5% e 10% de valores em falta. Para o c√°lculo dos indicadores de similaridade, opt√°mos por ignorar os valores em falta (na.rm = TRUE), utilizando apenas a informa√ß√£o dispon√≠vel em cada par de indiv√≠duos. Esta abordagem √© simples, evita imputa√ß√µes artificiais e garante que os resultados refletem apenas os dados observados. Nos casos em que n√£o existe variabilidade suficiente (por exemplo, indiv√≠duos com todos os valores iguais ou apenas valores em falta), o √≠ndice √© devolvido como NA, representando a incerteza da medida. Alternativamente, poderiam ser consideradas estrat√©gias como imputa√ß√£o pela m√©dia ou mediana dos biomarcadores, imputa√ß√£o baseada em modelos estat√≠sticos (regress√£o, kNN), ou mesmo imputa√ß√£o m√∫ltipla, que reflete a incerteza dos valores em falta. No entanto, para este trabalho, a op√ß√£o de ignorar os NA mostrou-se adequada, equilibrando simplicidade e robustez.


O tempo de computa√ß√£o √© muito demorado, demorando cerca de 30 segundos para computar as fun√ß√µes apenas para as primeiras 300 observa√ßoes (de um total de 50000).


# 3. Vectorization of the Function ----------------------------------------------


Completamente vetorizado:
```{r}
calc_similarity_vectorized <- function(dados) {
  n <- nrow(dados)
  p <- ncol(dados)
  X <- as.matrix(dados)
  
  # m√©dias por indiv√≠duo
  row_means <- rowMeans(X, na.rm = TRUE)
  
  ## 1. Dist√¢ncia Euclidiana
  sq <- rowSums(X^2, na.rm = TRUE)
  cross <- X %*% t(X)
  dist_sq <- outer(sq, sq, "+") - 2 * cross
  dist_sq[dist_sq < 0] <- 0
  dist_mat <- sqrt(dist_sq)
  
  ## 2. Correla√ß√£o de Pearson
  X_centered <- sweep(X, 1, row_means)
  cov_mat <- X_centered %*% t(X_centered)
  sd_vec <- sqrt(rowSums(X_centered^2, na.rm = TRUE))
  denom <- outer(sd_vec, sd_vec, "*")
  corr_mat <- cov_mat / denom
  corr_mat[denom == 0] <- NA
  
  ## 3. M√©dia das diferen√ßas absolutas (vers√£o vetorizada correta)
  Xi <- array(X, c(n, 1, p))          # (n,1,p)
  Xj <- array(X, c(1, n, p))          # (1,n,p)
  
  # replica√ß√£o expl√≠cita para broadcast
  Xi_exp <- Xi[, rep(1, n), , drop = FALSE]   # (n,n,p)
  Xj_exp <- Xj[rep(1, n), , , drop = FALSE]   # (n,n,p)
  
  diffs_abs <- abs(Xi_exp - Xj_exp)
  diffs_abs[is.na(diffs_abs)] <- NA
  mean_dif_mat <- apply(diffs_abs, c(1, 2), mean, na.rm = TRUE)
  
  ## 4. Contagem acima do limiar 
  threshold_mat <- outer(row_means, row_means, function(a,b) (a + b)/2)
  
  thresh_array <- array(threshold_mat, c(n, n, p))
  
  Xi2 <- Xi_exp
  Xj2 <- Xj_exp
  
  count_mat <- apply((Xi2 > thresh_array & Xj2 > thresh_array),
                     c(1,2), sum, na.rm = TRUE)
  
  ## 5. √çndice composto
  index_mat <- (dist_mat + abs(corr_mat) + mean_dif_mat) / (count_mat + 1)
  
  return(index_mat)
}
```


```{r}
matrix.vectorized <- calc_similarity_vectorized(dados)
```



Vers√£o menos vetorizada mas resolvendo o NA:

```{r}
calc_similarity_vectorized_partial <- function(dados) {
  n <- nrow(dados)
  X <- as.matrix(dados)
  
  # m√©dias por indiv√≠duo (ignora NAs)
  row_means <- rowMeans(X, na.rm = TRUE)
  
  ## 1. Dist√¢ncia Euclidiana
  dist_mat <- outer(1:n, 1:n,
                    Vectorize(function(i, j) {
                      xi <- X[i, ]
                      xj <- X[j, ]
                      valid_idx <- which(!is.na(xi) & !is.na(xj))
                      if (length(valid_idx) > 0) {
                        sqrt(sum((xi[valid_idx] - xj[valid_idx])^2))
                      } else {
                        NA
                      }
                    }))
  
  ## 2. Correla√ß√£o de Pearson
  corr_mat <- outer(1:n, 1:n,
                    Vectorize(function(i, j) {
                      xi <- X[i, ]
                      xj <- X[j, ]
                      valid_idx <- which(!is.na(xi) & !is.na(xj))
                      if (length(valid_idx) > 1) {
                        num <- sum((xi[valid_idx] - mean(xi[valid_idx])) *
                                   (xj[valid_idx] - mean(xj[valid_idx])))
                        den <- sqrt(sum((xi[valid_idx] - mean(xi[valid_idx]))^2)) *
                               sqrt(sum((xj[valid_idx] - mean(xj[valid_idx]))^2))
                        if (den == 0) NA else num / den
                      } else {
                        NA
                      }
                    }))
  
  ## 3. M√©dia das diferen√ßas absolutas
  mean_dif_mat <- outer(1:n, 1:n,
                        Vectorize(function(i, j) {
                          xi <- X[i, ]
                          xj <- X[j, ]
                          valid_idx <- which(!is.na(xi) & !is.na(xj))
                          if (length(valid_idx) > 0) {
                            mean(abs(xi[valid_idx] - xj[valid_idx]))
                          } else {
                            NA
                          }
                        }))
  
  ## 4. Contagem acima do limiar
  count_mat <- outer(1:n, 1:n,
                     Vectorize(function(i, j) {
                       xi <- X[i, ]
                       xj <- X[j, ]
                       valid_idx <- which(!is.na(xi) & !is.na(xj))
                       if (length(valid_idx) > 0) {
                         threshold <- (mean(xi[valid_idx]) + mean(xj[valid_idx])) / 2
                         sum((xi[valid_idx] > threshold) & (xj[valid_idx] > threshold))
                       } else {
                         NA
                       }
                     }))
  
  ## 5. √çndice composto
  index_mat <- (dist_mat + abs(corr_mat) + mean_dif_mat) / (count_mat + 1)
  
  return(index_mat)
}

```


```{r}
matrix.vectorized.partial <- calc_similarity_vectorized_partial(dados)
```



Tratamento de valores em falta (NA) na vetoriza√ß√£o: Na vers√£o vetorizada, verific√°mos inicialmente que qualquer observa√ß√£o com pelo menos um valor em falta propagava NA para todos os c√°lculos envolvendo essa linha, devido ao uso de opera√ß√µes matriciais (%*%, outer) que n√£o suportam o argumento na.rm. Para evitar este problema e manter consist√™ncia com a vers√£o baseada em loops, ajust√°mos a fun√ß√£o vetorizada de forma a calcular cada m√©trica apenas nos biomarcadores v√°lidos em comum entre dois indiv√≠duos. Assim, em cada par (ùëñ,ùëó), filtr√°mos os √≠ndices sem valores em falta e realiz√°mos os c√°lculos (dist√¢ncia euclidiana, correla√ß√£o de Pearson, m√©dia das diferen√ßas absolutas e contagem acima do limiar) apenas com os dados dispon√≠veis. Nos casos em que n√£o existia nenhum biomarcador v√°lido em comum, o resultado foi devolvido como NA, refletindo a aus√™ncia de informa√ß√£o suficiente. Esta abordagem √© equivalente √† usada nos loops, onde o argumento na.rm=TRUE permitia ignorar valores em falta em cada c√°lculo individual. A diferen√ßa √© que, na vetoriza√ß√£o, tivemos de implementar explicitamente a filtragem dos √≠ndices v√°lidos para replicar o mesmo comportamento. Desta forma, conseguimos aproveitar a informa√ß√£o parcial sem descartar indiv√≠duos, garantindo que os resultados da vers√£o vetorizada s√£o compar√°veis aos da vers√£o com loops.




# 4. Modular Programming -------------------------------------------------------

Looped version:

```{r}
dist_euclid_manual <- function(xi, xj) {
  dist_ij <- 0
  for (k in seq_along(xi)) {
    if (is.na(xi[k]) || is.na(xj[k])) next
    dist_ij <- dist_ij + (xi[k] - xj[k])^2
  }
  sqrt(dist_ij)
}

```

```{r}
corr_manual <- function(xi, xj, xi_mean, xj_mean) {
  num <- 0
  den_x <- 0
  den_y <- 0
  
  for (k in seq_along(xi)) {
    if (is.na(xi[k]) || is.na(xj[k])) next
    num   <- num   + (xi[k] - xi_mean) * (xj[k] - xj_mean)
    den_x <- den_x + (xi[k] - xi_mean)^2
    den_y <- den_y + (xj[k] - xj_mean)^2
  }
  
  denom <- sqrt(den_x) * sqrt(den_y)
  if (denom == 0) return(NA)
  num / denom
}

```

```{r}
mean_abs_diff_manual <- function(xi, xj, p) {
  mean_dif_sum <- 0
  
  for (k in seq_along(xi)) {
    if (is.na(xi[k]) || is.na(xj[k])) next
    mean_dif_sum <- mean_dif_sum + abs(xi[k] - xj[k])
  }
  
  mean_dif_sum / p   
}

```

```{r}
count_above_threshold_manual <- function(xi, xj, threshold) {
  count_ij <- 0
  
  for (k in seq_along(xi)) {
    if (is.na(xi[k]) || is.na(xj[k])) next
    if (xi[k] > threshold && xj[k] > threshold) {
      count_ij <- count_ij + 1
    }
  }
  
  count_ij
}

```

```{r}
compute_index_manual <- function(xi, xj) {
  p <- length(xi)
  
  xi_mean <- mean(xi, na.rm = TRUE)
  xj_mean <- mean(xj, na.rm = TRUE)
  threshold <- (xi_mean + xj_mean) / 2
  
  d  <- dist_euclid_manual(xi, xj)
  c  <- corr_manual(xi, xj, xi_mean, xj_mean)
  md <- mean_abs_diff_manual(xi, xj, p)
  ct <- count_above_threshold_manual(xi, xj, threshold)
  
  (d + abs(c) + md) / (ct + 1)
}

```

```{r}
calc_similarity_modular_loops <- function(dados) {
  n <- nrow(dados)
  S <- matrix(NA, n, n)
  
  for (i in 1:n) {
    xi <- as.numeric(dados[i, ])
    for (j in 1:n) {
      xj <- as.numeric(dados[j, ])
      S[i, j] <- compute_index_manual(xi, xj)
    }
  }
  
  S
}

```

```{r}
matrix.modular.loop <- calc_similarity_modular_loops(dados)
```



Fully Vectorized:


```{r}
dist_euclid_matrix <- function(X) {
  sq <- rowSums(X^2, na.rm = TRUE)
  cross <- X %*% t(X)
  dist_sq <- outer(sq, sq, "+") - 2 * cross
  dist_sq[dist_sq < 0] <- 0
  sqrt(dist_sq)
}
```

```{r}
correlation_matrix <- function(X) {
  row_means <- rowMeans(X, na.rm = TRUE)
  Xc <- sweep(X, 1, row_means)
  
  cov_mat <- Xc %*% t(Xc)
  sd_vec <- sqrt(rowSums(Xc^2, na.rm = TRUE))
  denom <- outer(sd_vec, sd_vec, "*")
  
  corr <- cov_mat / denom
  corr[denom == 0] <- NA
  corr
}

```

```{r}
mean_abs_diff_matrix <- function(X) {
  n <- nrow(X); p <- ncol(X)
  
  Xi <- array(X, c(n, 1, p))
  Xj <- array(X, c(1, n, p))
  
  Xi_exp <- Xi[, rep(1, n), , drop=FALSE]
  Xj_exp <- Xj[rep(1, n), , , drop=FALSE]
  
  diffs <- abs(Xi_exp - Xj_exp)
  apply(diffs, c(1, 2), mean, na.rm = TRUE)
}

```

```{r}
count_matrix <- function(X) {
  n <- nrow(X); p <- ncol(X)
  
  row_means <- rowMeans(X, na.rm = TRUE)
  threshold_mat <- outer(row_means, row_means, function(a,b) (a + b)/2)
  
  Xi <- array(X, c(n,1,p))
  Xj <- array(X, c(1,n,p))
  
  Xi_exp <- Xi[, rep(1,n), , drop=FALSE]
  Xj_exp <- Xj[rep(1,n), , , drop=FALSE]
  
  thresh_arr <- array(threshold_mat, c(n,n,p))
  
  apply((Xi_exp > thresh_arr & Xj_exp > thresh_arr), c(1,2), sum)
}

```

```{r}
calc_similarity_modular_vectorized <- function(dados) {
  X <- as.matrix(dados)
  
  dist_mat <- dist_euclid_matrix(X)
  corr_mat <- correlation_matrix(X)
  mean_dif_mat <- mean_abs_diff_matrix(X)
  count_mat <- count_matrix(X)
  
  (dist_mat + abs(corr_mat) + mean_dif_mat) / (count_mat + 1)
}

```

```{r}
matrix.modular.vectorized <- calc_similarity_modular_vectorized(dados)
```


Modular semi-vectorized:

```{r}
dist_euclid_na <- function(xi, xj) {
  valid_idx <- which(!is.na(xi) & !is.na(xj))
  if (length(valid_idx) > 0) {
    sqrt(sum((xi[valid_idx] - xj[valid_idx])^2))
  } else {
    NA
  }
}

```

```{r}
corr_pearson_na <- function(xi, xj) {
  valid_idx <- which(!is.na(xi) & !is.na(xj))
  if (length(valid_idx) > 1) {
    xi_v <- xi[valid_idx]
    xj_v <- xj[valid_idx]
    num <- sum((xi_v - mean(xi_v)) * (xj_v - mean(xj_v)))
    den <- sqrt(sum((xi_v - mean(xi_v))^2)) * sqrt(sum((xj_v - mean(xj_v))^2))
    if (den == 0) NA else num / den
  } else {
    NA
  }
}

```

```{r}
mean_abs_diff_na <- function(xi, xj) {
  valid_idx <- which(!is.na(xi) & !is.na(xj))
  if (length(valid_idx) > 0) {
    mean(abs(xi[valid_idx] - xj[valid_idx]))
  } else {
    NA
  }
}

```

```{r}
count_above_threshold_na <- function(xi, xj) {
  valid_idx <- which(!is.na(xi) & !is.na(xj))
  if (length(valid_idx) > 0) {
    threshold <- (mean(xi[valid_idx]) + mean(xj[valid_idx])) / 2
    sum((xi[valid_idx] > threshold) & (xj[valid_idx] > threshold))
  } else {
    NA
  }
}

```

```{r}
compute_index_na <- function(xi, xj) {
  d  <- dist_euclid_na(xi, xj)
  c  <- corr_pearson_na(xi, xj)
  md <- mean_abs_diff_na(xi, xj)
  ct <- count_above_threshold_na(xi, xj)
  (d + abs(c) + md) / (ct + 1)
}

```

```{r}
calc_similarity_modular_vectorized_partial <- function(dados) {
  n <- nrow(dados)
  X <- as.matrix(dados)
  index_mat <- matrix(NA, n, n)
  
  for (i in 1:n) {
    xi <- X[i, ]
    for (j in 1:n) {
      xj <- X[j, ]
      index_mat[i, j] <- compute_index_na(xi, xj)
    }
  }
  
  index_mat
}

```

```{r}
matrix.modular.vectorized.partial <- calc_similarity_modular_vectorized_partial(dados)
```


# 5. Visualization of the Results ----------------------------------------------


```{r}
library(ggplot2)
library(reshape2)


# Transformar para formato longo
df_plot <- melt(matrix.vectorized.partial)
colnames(df_plot) <- c("Ind1", "Ind2", "Index")

ggplot(df_plot, aes(x = Ind1, y = Ind2, fill = Index)) +
  geom_tile() +
  scale_fill_viridis_c(option = "plasma", na.value = "grey50") +
  labs(
    title = "Heatmap da Matriz de Similaridade",
    x = "Indiv√≠duo",
    y = "Indiv√≠duo",
    fill = "Index"
  ) +
  theme_minimal()

ggsave("heatmap.png",
       width = 12, height = 8, dpi = 300)

```

```{r}
ggplot(df_plot, aes(x = Index)) +
  geom_histogram(bins = 60, fill = "steelblue", color = "white") +
  theme_minimal() +
  xlim(0,100)
  labs(title = "Histograma do √çndice", x = "Index", y = "Frequ√™ncia")

```




Histogramas para cada m√©trica:

```{r}
# 1. Dist√¢ncia Euclidiana
dist_mat <- outer(1:nrow(dados), 1:nrow(dados),
                  Vectorize(function(i, j) dist_euclid_na(as.numeric(dados[i, ]), 
                                                          as.numeric(dados[j, ]))))
# 2. Correla√ß√£o
corr_mat <- outer(1:nrow(dados), 1:nrow(dados),
                  Vectorize(function(i, j) corr_pearson_na(as.numeric(dados[i, ]), 
                                                           as.numeric(dados[j, ]))))

# 3. M√©dia das diferen√ßas absolutas
mad_mat <- outer(1:nrow(dados), 1:nrow(dados),
                 Vectorize(function(i, j) mean_abs_diff_na(as.numeric(dados[i, ]), 
                                                           as.numeric(dados[j, ]))))

# 4. Contagem acima do limiar
count_mat <- outer(1:nrow(dados), 1:nrow(dados),
                   Vectorize(function(i, j) count_above_threshold_na(as.numeric(dados[i, ]), 
                                                                     as.numeric(dados[j, ]))))

```

```{r}
library(reshape2)

df_dist  <- melt(dist_mat);  names(df_dist)  <- c("Ind1","Ind2","Value")
df_corr  <- melt(corr_mat);  names(df_corr)  <- c("Ind1","Ind2","Value")
df_mad   <- melt(mad_mat);   names(df_mad)   <- c("Ind1","Ind2","Value")
df_count <- melt(count_mat); names(df_count) <- c("Ind1","Ind2","Value")

```

Distancia euclideana:
```{r}
a <- ggplot(df_dist, aes(x = Value)) +
  geom_histogram(bins = 60, fill = "steelblue", color = "white") +
  theme_minimal() +
  labs(title = "Histograma da Dist√¢ncia Euclidiana",
       x = "Dist√¢ncia", y = "Frequ√™ncia")

```

Correla√ß√£o de pearson
```{r}
a1 <- ggplot(df_corr, aes(x = Value)) +
  geom_histogram(bins = 60, fill = "darkgreen", color = "white") +
  theme_minimal() +
  labs(title = "Histograma da Correla√ß√£o",
       x = "Correla√ß√£o", y = "Frequ√™ncia")

```

M√©dia das diferen√ßas absolutas
```{r}
b <- ggplot(df_mad, aes(x = Value)) +
  geom_histogram(bins = 60, fill = "orange", color = "white") +
  theme_minimal() +
  labs(title = "Histograma da M√©dia das Diferen√ßas Absolutas",
       x = "Diferen√ßa M√©dia", y = "Frequ√™ncia")

```

Contagem acima do limiar
```{r}
c <- ggplot(df_count, aes(x = Value)) +
  geom_histogram(bins = 60, fill = "purple", color = "white") +
  theme_minimal() +
  labs(title = "Histograma da Contagem",
       x = "Contagem", y = "Frequ√™ncia")

```

Indice composto
```{r}
df_index <- melt(matrix.vectorized.partial)
colnames(df_index) <- c("Ind1", "Ind2", "Index")

d <- ggplot(df_index, aes(x = Index)) +
  geom_histogram(bins = 60, fill = "dodgerblue", color = "white") +
  theme_minimal() +
  labs(title = "Histograma do √çndice Composto",
       x = "√çndice", y = "Frequ√™ncia")

```

Grid dos histogramas:
```{r}
library(patchwork)
library(gridExtra)

grid <- grid.arrange(
  a, a1, b,
  c, d,
  ncol = 3
)

ggsave("histogramaslinha.png", 
       plot = grid,
       width = 12, height = 8, dpi = 300)

```



Boxplots para cada m√©trica:

Distancia euclideana
```{r}
e <- ggplot(df_dist, aes(y = Value)) +
  geom_boxplot(fill = "skyblue", alpha = .7) +
  theme_minimal() +
  labs(title = "Boxplot ‚Äî Dist√¢ncia Euclidiana",
       y = "Dist√¢ncia")

```

Correla√ß√£o de Pearson
```{r}
f <- ggplot(df_corr, aes(y = Value)) +
  geom_boxplot(fill = "seagreen", alpha = .7) +
  theme_minimal() +
  labs(title = "Boxplot ‚Äî Correla√ß√£o de Pearson",
       y = "Correla√ß√£o")

```

M√©dia das diferen√ßas absolutas
```{r}
g <- ggplot(df_mad, aes(y = Value)) +
  geom_boxplot(fill = "orange", alpha = .7) +
  theme_minimal() +
  labs(title = "Boxplot ‚Äî M√©dia das Diferen√ßas Absolutas",
       y = "Diferen√ßa M√©dia")

```

Contagem acima do limiar
```{r}
h <- ggplot(df_count, aes(y = Value)) +
  geom_boxplot(fill = "purple", alpha = .7) +
  theme_minimal() +
  labs(title = "Boxplot ‚Äî Contagem Acima do Limiar",
       y = "Contagem")

```

Indice composto
```{r}
i <- ggplot(df_plot, aes(y = Index)) +
  geom_boxplot(fill = "tomato", alpha = .7) +
  theme_minimal() +
  labs(title = "Boxplot do √çndice", y = "Index")

```

Grid dos boxplots
```{r}
library(patchwork)
library(gridExtra)

gridboxplots <- grid.arrange(
  e, f, g,
  h, i,
  ncol = 3
)

ggsave("meu_gridboxplots.png", 
       plot = gridboxplots,
       width = 12, height = 8, dpi = 300)

```


# 6. Comparison and Performance Analysis ---------------------------------------


```{r}
library(microbenchmark)
set.seed(123) 

mb_res <- microbenchmark(
  Loop= calc_similarity_loops(dados),
  VetorizadoCompleto = calc_similarity_vectorized(dados),
  VetorizadoParcial = calc_similarity_vectorized_partial(dados),
  ModularLoop = calc_similarity_modular_loops(dados),
  ModularVetorizadoCompleto=calc_similarity_modular_vectorized(dados),
  ModularVetorizadoParcial=calc_similarity_modular_vectorized_partial(dados),
  times = 10
)
autoplot <- autoplot(mb_res)


ggsave("autoplot.png", 
       plot = autoplot,
       width = 12, height = 8, dpi = 300)



```

```{r}
library(ggplot2)
library(dplyr)
library(scales)

# Converter microbenchmark para data.frame
df <- as.data.frame(mb_res)

# Criar o gr√°fico
ggplot(df, aes(x = expr, y = time / 1e6, fill = expr)) +   # converter ns ‚Üí ms
  geom_boxplot(outlier.alpha = 0.5) +
  coord_flip() +
  scale_fill_brewer(palette = "Dark2") +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    axis.title.y = element_blank(),
    axis.text.y = element_text(size = 11),
    panel.grid.minor = element_blank()
  ) +
  labs(
    title = "Compara√ß√£o de Desempenho (microbenchmark)",
    y = "Tempo (ms)"
  )

ggsave("autoplot2.png", 
       width = 12, height = 8, dpi = 300)
```

```{r}
library(ggplot2)
library(dplyr)
library(scales)

# Converter microbenchmark para data.frame
df <- as.data.frame(mb_res)

# Plot violin
ggplot(df, aes(x = expr, y = time / 1e6, fill = expr)) +   # ns ‚Üí ms
  geom_violin(trim = FALSE, alpha = 0.7) +
  geom_boxplot(width = 0.12, outlier.alpha = 0.4, color = "black") +
  coord_flip() +
  scale_fill_brewer(palette = "Dark2") +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    axis.title.y = element_blank(),
    axis.text.y = element_text(size = 11),
    panel.grid.minor = element_blank()
  ) +
  labs(
    title = "Distribui√ß√£o de Tempos (Violin + Boxplot)",
    subtitle = "Resultados do microbenchmark",
    y = "Tempo (ms)"
  )

ggsave("autoplot31.png", 
       width = 12, height = 8, dpi = 300)

```

```{r}
library(ggplot2)
library(dplyr)
library(scales)

# Converter microbenchmark para data.frame
df <- as.data.frame(mb_res)

ggplot(df, aes(x = expr, y = time / 1e6, fill = expr)) +   # ns ‚Üí ms
  geom_boxplot(outlier.alpha = 0.4) +
  coord_flip() +
  scale_fill_brewer(palette = "Dark2") +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    axis.title.y = element_blank(),
    axis.text.y = element_text(size = 11),
    panel.grid.minor = element_blank()
  ) +
  labs(
    title = "Compara√ß√£o de Desempenho (microbenchmark)",
    y = "Tempo (ms)"
  )

ggsave("autoplot4.png", 
       width = 12, height = 8, dpi = 300)
```










